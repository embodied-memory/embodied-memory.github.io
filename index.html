<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content=".">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Planning with an Embodied Learnable Memory</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="https://static.xx.fbcdn.net/rsrc.php/v4/y4/r/WUJbsVI4ruF.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      </a>

      
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Planning with an Embodied Learnable Memory</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Priyam Parashar<sup>*</sup>,</span>
            <span class="author-block">
              Jacob Krantz<sup>*</sup>,</span>
            <span class="author-block">
              Matthew Chang<sup>*</sup>,
            </span>
            <span class="author-block">
              Kavit Nilesh Shah<sup>2</sup>,
            </span>
            <span class="author-block">
              Xavier Puig<sup>+</sup>,
            </span>
            <span class="author-block">
              Roozbeh Mottaghi<sup>+</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">FAIR, Meta AI</span>
            <br>
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
            <span class="author-block"><sup>+</sup>Equal advising</span>
            <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" src="./static/images/cover_fig.png">
      </img>
      <h2 class="subtitle has-text-centered">
        We propose a learnable environment memory for embodied planning in dynamic scenes.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We develop an effective memory representation for embodied planning models performing 
            long-horizon mobile manipulation in dynamic, large-scale indoor environments. 
          </p>
          
          <p>
            Current memory representations often fall short in dynamic settings, struggling with updates 
            due to object movements, perception noise, and computational deficiencies. 
            To overcome these limitations, we propose the PerceptionCache, 
            a novel learnable external memory designed for embodied planning tasks. 
            PerceptionCache is implemented as a Vision Language Model (VLM) that utilizes 
            egocentric visual observations to maintain and update a textual representation of the environment. 
            We further introduce two complementary training methods to better utilize the PerceptionCache: 
            a human-in-the-loop strategy that leverages human-collected trajectories for natural exploration 
            and interaction, and a reinforcement learning approach, which efficiently improves planning performance 
            utilizing difficulty-aware exploration. 
          </p>
          <p>
            Our results demonstrate significant improvements in perception, planning, and sim-to-real transfer, 
            highlighting the robustness and adaptability of PerceptionCache in dynamic environments.
          </p>
          
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
        
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      
          <h2 class="title is-3">Perception Cache: A Learnable Memory</h2>
      </div>
    </div>
      <div class="columns is-centered">
      
        <div class="column is-half">
          <p>
          We train a VLM to build a representation of the environment. At each observation the VLM updates its 
          memory by adding newly seen objects, or updating the information of previously seen objects. 
         </p>
         <p></p> 
          This information is represented as text, which an LLM uses to plan actions in the environment. 
         
         </p>
        </div>
        <div class="column is-half has-text-centered">
          <img id="teaser" src="./static/images/cache_overview.png">
          </img>
          
        </div>
        
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Improving planning with DDAFT</h2>
        <div class="content has-text-justified">
          <p>
            We introduce a novel approach to finetune LLMs for embodied planning via reward-free RL. Our approach, 
            DDAFT (Difficulty-Aware Data Augmentation for Fine-Tuning), samples diverse planning trajectories on tasks that 
            the planning has low success in, and uses task reward to augment the training data.
          </p>
          <p>
            DDAFT improves planning performance across a wide variety of settings, 
            including with ground-truth perception, outputs from PerceptionCache and on pre-trained LLMs as well or LLMs trained on human planning data.
          </p>
          
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Training with Human-In-The-Loop Data</h2>
        <div class="content has-text-justified">
          <p>
            We also explore human data to improve planning performance on embodied tasks. Using the HITL data from PARTNR, 
            we train an LLM to perform planning in partially observed environments. Training with human data improves planning performance,
            by X% with privileged perception and by Y% with PerceptionCache.
          </p>
         
          
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
